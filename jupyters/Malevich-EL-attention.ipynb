{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724505ef",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1AoolDYePUpPkRCKIu0cP9zV7lX5QGD3Z?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5280201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ax37/code/py/rudallel\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2f5594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c anaconda cudatoolkit=10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d097c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62713d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: rudalle 1.1.0rc0\r\n",
      "Uninstalling rudalle-1.1.0rc0:\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y rudalle\n",
    "!pip install -e .  # rudalle==0.0.1rc8 > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@param {type: \"float\"}\n",
    "ALLOWED_MEMORY = 6.5 # 3.5 # choose your GPU memory in GB  \n",
    "if ALLOWED_MEMORY < 4.5:\n",
    "    DALLE_BS = 1\n",
    "elif ALLOWED_MEMORY < 5.5:\n",
    "    DALLE_BS = 2\n",
    "elif ALLOWED_MEMORY < 6.5:\n",
    "    DALLE_BS = 3\n",
    "elif ALLOWED_MEMORY < 7.5:\n",
    "    DALLE_BS = 4\n",
    "elif ALLOWED_MEMORY < 8.5:\n",
    "    DALLE_BS = 5\n",
    "elif ALLOWED_MEMORY < 9.5:\n",
    "    DALLE_BS = 6\n",
    "elif ALLOWED_MEMORY < 10.5:\n",
    "    DALLE_BS = 7\n",
    "else:\n",
    "    DALLE_BS = 8\n",
    "    \n",
    "print('ruDALL-E batch size:', DALLE_BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import torch\n",
    "from psutil import virtual_memory\n",
    "\n",
    "\n",
    "ram_gb = round(virtual_memory().total / 1024**3, 1)\n",
    "print('CPU:', multiprocessing.cpu_count())\n",
    "print('RAM GB:', ram_gb)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b821402",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f695db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import more_itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from rudalle.pipelines import generate_images, show  # , cherry_pick_by_clip\n",
    "from rudalle import get_rudalle_model, get_tokenizer, get_vae  # , get_ruclip\n",
    "from rudalle.utils import seed_everything, torch_tensors_to_pil_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare models:\n",
    "device = \"cuda\"\n",
    "dalle = get_rudalle_model(\"Malevich\", pretrained=True, fp16=True, device=device)\n",
    "tokenizer = get_tokenizer()\n",
    "vae = get_vae(dwt=True)\n",
    "\n",
    "# # prepare utils:\n",
    "# ruclip, ruclip_processor = get_ruclip(\"ruclip-vit-base-patch32-v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a44e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rudalle.dalle.transformer import ELAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490dff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# torch.set_grad_enabled(False)\n",
    "# att1 = dalle.module.transformer.layers[0].attention\n",
    "# att1.custom_relax = False\n",
    "# att1.cogview_pb_relax = False\n",
    "# att1.eval()\n",
    "# att1.attention_dropout = torch.nn.Identity()\n",
    "# att2 = ELAttention(att1)\n",
    "# torch.manual_seed(42)\n",
    "# inputs = (torch.randn((2, 4, dalle.module.transformer.layers[0].attention.hidden_size)).cuda().half(),\n",
    "#           torch.ones((1, 1, 4, 4)).cuda().half())\n",
    "# x1, _ = att1(*inputs, use_cache=True)\n",
    "# x2, _ = att2(*inputs, use_cache=True)\n",
    "# diff = x1 - x2\n",
    "# print((diff ** 2).sum())\n",
    "\n",
    "# diff = diff.clamp(-4, 4)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(diff.reshape(-1, diff.shape[-1] // 16).detach().float().cpu().numpy() ** 2)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69326e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.cuda()\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cb660",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    dalle.module.transformer.to_el()\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1946b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dalle.module.transformer.layers[0].attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b73e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"эль-внимание\"\n",
    "\n",
    "seed_everything(14)\n",
    "images = []\n",
    "for top_k, top_p, images_num in [\n",
    "    (2048, 0.995, 8),\n",
    "#     (1536, 0.99, 8),\n",
    "#     (1024, 0.99, 8),\n",
    "#     (1024, 0.98, 8),\n",
    "#     (512, 0.97, 8),\n",
    "#     (384, 0.96, 8),\n",
    "#     (256, 0.95, 8),\n",
    "#     (128, 0.95, 8),\n",
    "]:\n",
    "    images += generate_images(text, tokenizer, dalle, vae,\n",
    "                                 top_k=top_k, images_num=images_num,\n",
    "                                 top_p=top_p, bs=DALLE_BS,\n",
    "                                 use_cache=True)\n",
    "show(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec488a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_images = []\n",
    "for _codebooks in tqdm(torch.cat(codebooks).cpu()):\n",
    "    with torch.no_grad():\n",
    "        images = vae.decode(_codebooks.unsqueeze(0))\n",
    "        pil_images += torch_tensors_to_pil_list(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
